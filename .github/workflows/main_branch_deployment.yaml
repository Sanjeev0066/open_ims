name: Deploy to digital ocean
run-name: ${{ github.actor }}'s merge - Deployment to Digital Ocean

# env:
#   SERVER: production

# on:
#   push:
#     branches:
#       - main

on:
  pull_request:
    types:
      - closed
    branches:
      - main
jobs:
  update_deployed_tags_branch:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    steps:
      #! If there has been a lot of commits made to the tag repository after a PR has been opened 
      #! then we may face the issue that 20 commits back may not contain the correct commit for the "old" PR
      #? We can most likely just catch this step if it errors and then re-try with a higher fetch depth (example in comment below), like 50, 100, 200, 500, 
      #? and then 0 incase this project is so massive lol and this will fetch all the commit history for the branch
      #? The commit history required to be fetched can be reduced in the future by using release branches for the production-image-tag repo but
      #? we'll cross that bridge when we get to it......
      - name: Checkout repository with production tags
        uses: actions/checkout@v4
        with:
          repository: ferncabrera/ccg-prod-tags
          token: ${{ secrets.GH_PAT }}
          ref: master
          path: ccg-prod-tags
          fetch-depth: 25
      - run: |
          cd ${{github.workspace}}/ccg-prod-tags
          git config user.name ferncabrera
          SHA_SHORT=$(git rev-parse --short ${{github.event.pull_request.head.sha}})
          git config user.email ferncabreradeveloper@gmail.com
          git fetch origin ccg-deployed-tags --depth=1
          git checkout ccg-deployed-tags 
          git checkout ":/PR ${{github.repository}}#${{github.event.number}} now @ HEAD_COMMIT ${{github.repository}}@${{github.event.pull_request.head.sha}}" production-deployment-tags.json
          git commit -m "MERGE for PR ${{github.repository}}#${{github.event.number}} @ HEAD_COMMIT ${{github.repository}}@${{github.event.pull_request.head.sha}}"
          git push
        # git commit -m "MERGED PR #${{github.event.number}} @ HEAD_COMMIT ${SHA_SHORT} into ${{github.event.pull_request.head.ref}}!" -m "Merged PR ref: ${{github.repository}}#${{github.event.number}}; HEAD_COMMIT ref: ${{github.repository}}@${{github.event.pull_request.head.sha}}"

  main_branch_deployment:
    needs: update_deployed_tags_branch
    if: github.event.pull_request.merged == true
    # main_branch_deployment:
    runs-on: ubuntu-latest
    steps:

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
          echo "$(<kubectl.sha256) kubectl" | sha256sum --check

          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          kubectl version --client

      - name: Install Skaffold
        run: |
          curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && \
          sudo install skaffold /usr/local/bin/
          skaffold version

      - name: Cache skaffold image builds & config
        uses: actions/cache@v3
        with:
          path: ~/.skaffold/
          key: fixed-${{ github.sha }}

      # - name: Set up Docker Buildx
      #   uses: docker/setup-buildx-action@v3

      - name: Login to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Checkout on Digital Ocean K8s Cluster
        uses: actions/checkout@v4
        with:
          path: main

      #! If there has been a lot of commits made to the tag repository after a PR has been opened 
      #! then we may face the issue that 20 commits back may not contain the correct commit for the "old" PR
      #? We can most likely just catch this step if it errors and then re-try with a higher fetch depth (example in comment below), like 50, 100, 200, 500, 
      #? and then 0 incase this project is so massive lol and this will fetch all the commit history for the branch
      #? The commit history required to be fetched can be reduced in the future by using release branches for the production-image-tag repo but
      #? we'll cross that bridge when we get to it......
      - name: Checkout repository with production tags
        uses: actions/checkout@v4
        with:
          repository: ferncabrera/ccg-prod-tags
          token: ${{ secrets.GH_PAT }}
          ref: ccg-deployed-tags
          path: ccg-prod-tags
          fetch-depth: 10
      - run: |
          cd ${{github.workspace}}/ccg-prod-tags
          SHA_SHORT=$(git rev-parse --short ${{github.event.pull_request.head.sha}})
          git checkout ":/MERGE for PR ${{github.repository}}#${{github.event.number}} @ HEAD_COMMIT ${{github.repository}}@${{github.event.pull_request.head.sha}}"
          echo "Deploying the following JSON production tags file:"
          cat production-deployment-tags.json

      #! Noting this here for later, we can handle errors during GA execution with the following 3 lines!
      # - name: My backup step
      #   if: ${{ failure() }}
      #   uses: actions/heroku@1.0.0

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Save DigitalOcean kubeconfig with short-lived credentials
        run: doctl kubernetes cluster kubeconfig save --expiry-seconds 600 k8s-ccg-ims

      - name: Deploy to DigitalOcean Kubernetes
        run: |
          cd ${{github.workspace}}/main
          skaffold deploy -p prod-do --build-artifacts='${{github.workspace}}/ccg-prod-tags/production-deployment-tags.json'

      #? We should look into verifying the deployments after, this way we can also roll-back on deployments perhaps...
      # - name: Verify deployment
      #   run: kubectl rollout status deployment/appname -n appname
      # Need to install doctl 


    # skaffold build -p prod --file-output='production-tags.json'
    # skaffold deploy -p prod --build-artifacts='production-tags.json' --tail
# skaffold verify -p staging
# skaffold delete -p staging 
